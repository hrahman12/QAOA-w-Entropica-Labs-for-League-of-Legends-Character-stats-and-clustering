{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec17a05-13c9-4ed2-8909-98fba3f6c4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure to install entropica on device\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('QAOA/data/leagueoflegends.csv')#file path of csv\n",
    "df = df.set_index('#') #index character by their ID number\n",
    "df = df.rename_axis('ID') #rename axis to 'ID' instead of '#'\n",
    "df = df.loc[~df.index.duplicated(keep='first')] #drop duplicates\n",
    "df.head()\n",
    "\n",
    "df = df.loc[df['Generation']<=3]\n",
    "df.sample(frac=1).head() #sample the whole dataset (frac=1) to shuffle the arrangement\n",
    "\n",
    "print('Percent of Non-Legendary Champions: %.2f' %((df.Legendary.count()-df.Legendary.sum())/df.Legendary.count()))\n",
    "print('Percent of Legendary Champions: %.2f' %((df.Legendary.sum())/df.Legendary.count()))\n",
    "\n",
    "legendary = df.loc[df['Legendary'] == True].sample(5)\n",
    "non_legendary = df.loc[df['Legendary'] == False].sample(5)\n",
    "league = pd.concat([legendary,non_legendary])\n",
    "\n",
    "numerical_columns = ['Total','HP','Attack','Defense','Sp. Atk','Sp. Def','Speed']\n",
    "\n",
    "labels = league['Legendary']\n",
    "data = league[numerical_columns].copy()\n",
    "data.head()\n",
    "\n",
    "from entropica_qaoa.utilities import distances_dataset\n",
    "\n",
    "dist = pd.DataFrame(distances_dataset(data.values),\n",
    "                       index=data.index,columns=data.index)\n",
    "dist.iloc[0:5, 0:5]\n",
    "\n",
    "df.loc[dist.index].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cbf30f-63e5-4d9f-acde-3705ad0b79cc",
   "metadata": {},
   "source": [
    "PYQUIL Portion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f2c9b9-47dc-4478-b0b0-2d94697112ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyquil.api import WavefunctionSimulator\n",
    "from pyquil.paulis import PauliSum, PauliTerm\n",
    "\n",
    "#Constructing a quadratic PauliTerm\n",
    "i = 3\n",
    "j = 6\n",
    "print('Distance between samples %d and %d: %.3f' %(i,j,dist.values[i][j]))\n",
    "\n",
    "term1 = PauliTerm(\"Z\",i,dist.values[i][j])\n",
    "term2 = PauliTerm(\"Z\",j,1.0) \n",
    "term = term1*term2\n",
    "print(term)\n",
    "\n",
    "from entropica_qaoa.utilities import hamiltonian_from_distances\n",
    "\n",
    "hamiltonian = hamiltonian_from_distances(dist)\n",
    "print(hamiltonian)\n",
    "\n",
    "# import the neccesary pyquil modules\n",
    "from entropica_qaoa.qaoa.cost_function import QAOACostFunctionOnQVM, QAOACostFunctionOnWFSim\n",
    "\n",
    "# import QAOAParameters \n",
    "from entropica_qaoa.qaoa.parameters import ExtendedParams\n",
    "\n",
    "# import an optimizer\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "#Some utilities for time tracking and measuring our outcomes.\n",
    "import time\n",
    "from math import log\n",
    "from entropica_qaoa.utilities import cluster_accuracy, max_probability_bitstring\n",
    "\n",
    "\n",
    "timesteps = 3 # The QAOA p parameter\n",
    "iters = 500 # Number of classical optimiser iterations\n",
    "n_qubits = 10 #this number might be defined before your dataset - should equal the number of data points\n",
    "#The hamiltonian is also a hyperparameter\n",
    "\n",
    "betas = [round(val,1) for val in np.random.rand(timesteps*n_qubits)]\n",
    "gammas_singles = [round(val,1) for val in np.random.rand(0)] #we don't want any bias terms\n",
    "gammas_pairs = [round(val,1) for val in np.random.rand(timesteps*len(hamiltonian))]\n",
    "\n",
    "hyperparameters = (hamiltonian, timesteps)\n",
    "parameters = (betas, gammas_singles, gammas_pairs)\n",
    "\n",
    "params = ExtendedParams(hyperparameters, parameters)\n",
    "\n",
    "# Set up the WavefunctionSimulator from pyQuil\n",
    "sim = WavefunctionSimulator()\n",
    "cost_function = QAOACostFunctionOnWFSim(hamiltonian,\n",
    "                                        params=params,\n",
    "                                        sim=sim,\n",
    "                                        enable_logging=True)\n",
    "\n",
    "t0 = time.time()\n",
    "res = minimize(cost_function, params.raw(), tol=1e-3, method='Cobyla',\n",
    "               options={\"maxiter\": iters})\n",
    "print('Run complete!\\n','Runtime:','{:.3f}'.format(time.time()-t0))\n",
    "\n",
    "wave_func = cost_function.get_wavefunction(params.raw())\n",
    "lowest = max_probability_bitstring(wave_func.probabilities())\n",
    "\n",
    "true_clusters = [1 if val else 0 for val in labels] \n",
    "acc = cluster_accuracy(lowest,true_clusters)\n",
    "\n",
    "print('Cost Function Value:', res.fun)\n",
    "print('Converged?:',res.message)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PennyLane",
   "language": "python",
   "name": "pennylane"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
